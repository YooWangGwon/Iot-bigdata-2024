{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이토치 기본\n",
    "- 기본사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 파이토치 버전 확인\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파이토치 패키지 구성\n",
    "- **torch**\n",
    "    - 메인 네임스페이스. 텐서(진짜 기본!!) 및 수학함수(sin, cos, tan...) 포함. Numpy와 유사한 구조\n",
    "    - Numpy와 쉽게 변환\n",
    "\n",
    "- **torch.autograd**\n",
    "    - 자동 미분(!)을 위한 함수 포함. 컨텍스트 매니저, 기반 클래스 및 함수 포함\n",
    "\n",
    "- **torch.nn / torch.nnfunctional**\n",
    "    - nn(Neural Network). 딥러닝 신경망을 구축시 필요한 데이터구조, 레이어 정의가 포함. BNN, LSTM 레이어 및 ReLU, MESLoss 등 TensorFlow에 있는 함수 및 모델 포함\n",
    "        - BNN: Bayesian Neural Networks는 **모델의 불확실성**을 추정할 수 있는 신경망. PyTorch에서 직접 지원하지 않지만, Pyro 등을 사용하여 구현 가능\n",
    "        - LSTM: Long Short-Term Memory는 **장기 종속성을 학습**할 수 있는 순환 신경망\n",
    "        - ReLU: Rectified Linear Unit은 신경망에서 **비선형성**을 도입하여 신경망이 복잡한 함수 근사치를 학습할 수 있게 해주는 활성화 함수\n",
    "        - MSELoss: Mean Squared Error Loss는 회귀 문제에서 예측 값과 실제 값의 차이의 제곱 평균을 계산하여 측정하는 손실 함수\n",
    "\n",
    "- **torch.optim**\n",
    "    - 확률적 경사 하강법(Stochastic Gradient Descent, SGD) 중심 파라미터 최적화 알고리즘 포함\n",
    "\n",
    "- **torch.utils.data**\n",
    "    - SGD 반복 연산 시 Batch(컴퓨터 자동 백그라운드로 실행) 유틸리티가 포함\n",
    "\n",
    "- **torch.onnx**\n",
    "    - Open Neural Network eXchange 포맷의 모델 포함. onnx 확장자로 export하면 Tensorflow나 다른 딥러닝, 머신러닝 라이브러리에서 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 파이토치 기초\n",
    "\n",
    "##### 텐서(Tensor)\n",
    "- 파이토치에서 데이터를 저장하는 자료구조\n",
    "- 텐서플로도 기본 텐서, Numpy와 성격과 사용법이 흡사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1차원 크기 3의 배열을 넘파이로\n",
    "data = [1,3,5]\n",
    "np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1차원 크기 3의 배열을 텐서로\n",
    "torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4], [5, 6, 7, 8]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 파이썬의 2차원 리스트\n",
    "arr = [[1,2,3,4],[5,6,7,8]]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2차원 2행 4열 넘파이\n",
    "np2_data = np.array(arr)\n",
    "np2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2차원 2행4열 텐서\n",
    "tc2_data = torch.tensor(arr)\n",
    "tc2_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 텐서의 구조 명칭\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/814efc38b1d8ae9cf47a24e12c8aae325fb3ab56e04c601d98c967d2a182e758/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6875676f4d4753756e672f73747564792d7079746f7263682f6d61696e2f696d616765732f746f726368303030332e706e67\" width=\"730\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1차원 텐서 -> 벡터(Vector)\n",
    "- 2차원 텐서 -> 매트릭스(Matrix)\n",
    "- 3차원 텐서 -> 텐서(Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "## 넘파이와 파이토치의 배열 크기\n",
    "print(np2_data.shape, tc2_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32 torch.int64\n"
     ]
    }
   ],
   "source": [
    "## 넘파이는 정수의 기본타입이 int32, 파이토치는 정수 기본타입이 int64\n",
    "print(np2_data.dtype, tc2_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.],\n",
       "        [5., 6., 7., 8.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 텐서를 만들 때 타입을 지정해서 생성 가능\n",
    "tc2_data = torch.tensor(data=arr, dtype=torch.float64)\n",
    "tc2_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 텐서의 데이터 타입\n",
    "- 실수 계산 시 FloatTensor, 정수를 사용할 때는 LongTensor, True/False는 ByteTensor 사용\n",
    "- 객체클래스  |  데이터 타입\n",
    "- ByteTensor, CharTensor - int8\n",
    "- ShortTensor   - int16\n",
    "- IntTensor     - int32\n",
    "- LongTensor    - int64\n",
    "- HalfTensor    - float16\n",
    "- FloatTensor   - float32\n",
    "- DoubleTensor  - float64\n",
    "\n",
    "- 참조 : https://subinium.github.io/pytorch-Tensor-Variable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.],\n",
       "        [5., 6., 7., 8.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 데이터타입으로 변환시, 43번 셀과 동일한결과\n",
    "tc2_data.type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 텐서 구조, 상태 확인\n",
    "- tensor.shape, tensor.size() - 텐서의 크기\n",
    "- tensor.dtype, sensor.type() - 텐서의 데이터타입 확인\n",
    "    - dtype:일반적인 데이터 타입, type():객체의 클래스 타입\n",
    "- tensor.ndim, tensor.dim() - 텐서의 차원\n",
    "- tensor.numel() - 전체 원소 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5, 7, 9])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "tns1_data = torch.tensor([1,3,5,7,9])\n",
    "tns1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "tns2_data = torch.tensor([[1,2,3,4],[5,6,7,8]])\n",
    "tns2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8]],\n",
       "\n",
       "        [[ 9, 10, 11],\n",
       "         [12, 13, 14],\n",
       "         [15, 16, 17]],\n",
       "\n",
       "        [[18, 19, 20],\n",
       "         [21, 22, 23],\n",
       "         [24, 25, 26]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 넘파이로 3차원 생성, Tensor\n",
    "tns3_data = torch.tensor(np.arange(27).reshape(3,3,3))\n",
    "tns3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector - 5 \n",
      "matrix - 8 \n",
      "tensor - 27\n"
     ]
    }
   ],
   "source": [
    "## 원소 개수\n",
    "print(f'Vector num - {tns1_data.numel()} \\nMatrix num - {tns2_data.numel()} \\nTensor num - {tns3_data.numel()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 차원확인\n",
    "tns1_data.ndim, tns2_data.ndim, tns3_data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 위와 동일\n",
    "tns1_data.dim(), tns2_data.dim(), tns3_data.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.LongTensor', 'torch.LongTensor', 'torch.IntTensor')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 차원확인\n",
    "tns1_data.type(), tns2_data.type(), tns3_data.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5]), torch.Size([2, 4]), torch.Size([3, 3, 3]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 차원확인\n",
    "tns1_data.shape, tns2_data.shape, tns3_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 넘파이아 파이토치 텐서간 변한 쉬움\n",
    "- 넘파이 함수와 동일한 함수 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## zeros\n",
    "torch.zeros(2,4), torch.ones(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]]]),\n",
       " tensor([[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]],\n",
       " \n",
       "         [[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,3,3), torch.ones(3,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 파이썬 리스트의 인덱싱, 슬라이싱 전부 가능\n",
    "tns2_data[0][1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  4,  6],\n",
       "        [ 8, 10, 12]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 행렬합\n",
    "x1 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "torch.add(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4,  9],\n",
       "        [16, 25, 36]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 행렬곱\n",
    "torch.mul(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22, 28],\n",
       "        [49, 64]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 매트릭스 연산, 첫번째 매트릭스 열크기와, 두번째 매트릭스 행 크기가 일치\n",
    "x3 = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "torch.mm(x1,x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CPU 메모리에서 GPU 메모리도 데이터 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 현재의 데이터가 어느 메모리에 있는지 확인\n",
    "x3.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CPU 디바이스 = 'cpu'ArithmeticError\n",
    "cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU 디바이스 = 'cuda'\n",
    "gpu = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]], device='cuda:0')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4 = x3.to(gpu)\n",
    "x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x5 = x4.to(cpu)\n",
    "x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아직도 텐서와 기본 함수가 엄청 많음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
